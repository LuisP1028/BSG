<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bayesian Modeling & Computation: Study Guide</title>
<style>
    /* 
       --- EDITABLE CHUNK START --- 
       Modify these variables to change the color scheme.
    */
    :root {
        --bg-color: #000000;           /* Pure Black Background */
        --text-color: #00ff41;         /* Terminal Green Text */
        --accent-color: #00ff41;       /* Bright Green Accents */
        --dim-color: #003b00;          /* Dark Green for subtle borders */
        --border-color: #00ff41;       /* Green Borders */
        --font-main: 'Courier New', Courier, monospace;
        --font-header: 'Arial Black', Impact, sans-serif;
    }

    * { box-sizing: border-box; }

    body {
        margin: 0;
        padding: 0;
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: var(--font-main);
        line-height: 1.5;
        overflow-x: hidden; /* Prevents horizontal scroll on mobile */
    }

    /* --- DITHERPUNK VISUALS (Green Mode) --- */
    
    /* Background Dither Simulation */
    .dither-layer {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: -1;
        /* Updated to Green dither dots */
        background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
        background-size: 4px 4px;
        opacity: 0.4;
    }

    /* Scanline Overlay */
    .scanlines {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        /* Green-tinted scanlines */
        background: linear-gradient(
            to bottom, 
            rgba(0, 255, 65, 0), 
            rgba(0, 255, 65, 0) 50%, 
            rgba(0, 20, 0, 0.2) 50%, 
            rgba(0, 20, 0, 0.2)
        );
        background-size: 100% 4px;
        pointer-events: none;
        z-index: 9999;
    }

    /* --- RESPONSIVE CONTAINER --- */
    .container {
        max-width: 900px;         /* Limits width on large screens */
        width: 100%;              /* Ensures it takes full width on small screens */
        margin: 0 auto;
        padding: 40px 20px;
        border-left: 2px dashed var(--dim-color);
        border-right: 2px dashed var(--dim-color);
        background-color: rgba(0, 10, 0, 0.9); /* Very dark green background tint */
        min-height: 100vh;
    }

    /* Typography */
    h1 {
        font-family: var(--font-header);
        text-transform: uppercase;
        font-size: 3rem;
        border-bottom: 5px solid var(--accent-color);
        margin-bottom: 40px;
        letter-spacing: -2px;
        text-shadow: 0px 0px 8px var(--accent-color); /* Green Glow */
        color: var(--accent-color);
        text-align: center;
        word-wrap: break-word; /* Prevents long words breaking layout */
    }

    h3 { margin-top: 0; color: var(--accent-color); text-transform: uppercase; }

    strong { color: var(--accent-color); text-decoration: underline; }
    em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

    /* --- ACCORDION SYSTEM --- */

    /* PART LEVEL (Outer) */
    details.part {
        margin-bottom: 30px;
        border: 2px solid var(--border-color);
        background: #000;
        box-shadow: 6px 6px 0px var(--dim-color);
        transition: transform 0.1s;
    }
    
    details.part[open] {
        box-shadow: 4px 4px 0px var(--dim-color);
        transform: translate(2px, 2px);
    }

    details.part > summary {
        font-family: var(--font-header);
        font-size: 1.5rem;
        padding: 15px 20px;
        background-color: var(--accent-color);
        color: var(--bg-color); /* Black text on Green background */
        cursor: pointer;
        list-style: none;
        text-transform: uppercase;
        position: relative;
    }

    details.part > summary::-webkit-details-marker { display: none; }
    
    details.part > summary::after {
        content: '+'; 
        position: absolute; right: 20px; font-weight: 900;
    }
    details.part[open] > summary::after { content: '-'; }

    .part-content { padding: 20px; border-top: 2px solid var(--border-color); }
    
    .focus-line {
        display: block;
        font-size: 0.8rem;
        text-transform: uppercase;
        letter-spacing: 2px;
        margin-bottom: 20px;
        color: #008f11;
        font-weight: bold;
    }

    /* SECTION LEVEL (Middle) */
    details.section {
        margin-bottom: 15px;
        border: 1px solid var(--dim-color);
        background: #050505;
    }

    details.section > summary {
        font-family: var(--font-main);
        font-weight: bold;
        padding: 12px;
        background: #0a0a0a;
        color: var(--text-color);
        cursor: pointer;
        list-style: none;
        border-bottom: 1px solid transparent;
        text-transform: uppercase;
        font-size: 1.1rem;
    }

    details.section > summary:hover { 
        background: var(--dim-color); 
        color: var(--accent-color); 
    }
    details.section[open] > summary {
        border-bottom: 1px solid var(--dim-color);
        background: #0f0f0f;
        color: var(--accent-color);
        text-shadow: 0px 0px 5px var(--accent-color);
    }

    .section-content { padding: 20px; }

    /* SUBSECTION / CONTENT BLOCKS */
    .subsection {
        margin-bottom: 25px;
        border-left: 4px solid var(--dim-color);
        padding-left: 15px;
    }

    .subsection-title {
        background: var(--dim-color);
        color: var(--accent-color);
        padding: 2px 6px;
        font-weight: bold;
        text-transform: uppercase;
        display: inline-block;
        margin-bottom: 10px;
        font-size: 0.9rem;
    }

    p { margin-bottom: 12px; margin-top: 0; text-align: justify; }
    
    ul { padding-left: 20px; margin-bottom: 15px; }
    li { margin-bottom: 5px; }

    /* Code/Math styling */
    .code-block {
        background: #020a02;
        border: 1px dashed var(--dim-color);
        padding: 10px;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
        color: var(--accent-color);
        overflow-x: auto; /* Ensures horizontal scrolling on small screens */
        white-space: pre-wrap; /* Wraps text if possible */
    }

    /* --- RESPONSIVE ADJUSTMENTS --- */
    @media (max-width: 600px) {
        h1 { font-size: 1.8rem; border-bottom-width: 3px; }
        details.part > summary { font-size: 1.1rem; padding: 12px; }
        details.section > summary { font-size: 0.9rem; }
        .container { padding: 10px; border: none; }
        .part-content, .section-content { padding: 10px; }
        p { text-align: left; } /* Justify can look weird on mobile */
    }
    /* --- END EDITABLE CHUNK --- */
</style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<div class="container">
    <h1>Bayesian Modeling<br>& Computation</h1>

    <!-- PART I -->
    <details class="part">
        <summary>Part I: Bayesian Foundations</summary>
        <div class="part-content">
            <span class="focus-line">Focus: Concepts, MCMC, Priors</span>

            <!-- SECTION 1 -->
            <details class="section">
                <summary>1. Key Bayesian Concepts</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">Prior</span>
                        <p>The prior distribution represents initial beliefs about model parameters before observing any data. It encodes pre-existing knowledge or assumptions about parameter values.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Observed data</span>
                        <p>Observed data are the actual measurements, used to update prior beliefs via the likelihood function in Bayesian inference.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Prior predictive distribution</span>
                        <p>The distribution of data that the model would generate based solely on the prior beliefs about parameters, before observing any actual data.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Marginal likelihood</span>
                        <p>The probability of the observed data under the model.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Computing expectations</span>
                        <p>The average outcome of a quantity (like a parameter or prediction) under the posterior or predictive distribution.</p>
                    </div>
                </div>
            </details>

         <!-- SECTION 2 -->
<details class="section">
    <summary>2. MCMC & Metropolis Hastings</summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">Markov Chain Monte Carlo (MCMC)</span>
            <p>MCMC approximates the posterior by building a chain of samples. It iteratively proposes and accepts guesses to map the distribution's shape</p>
            <p>The posterior is a mathematical function representing your updated beliefs.</p>
        </div>
        <div class="subsection">
            <span class="subsection-title">Metropolis Hastings [ACCEPTING/REJECTING SAMPLES]</span>
            <p>Metropolis-Hastings acts like an explorer mapping a probability landscape. From its current spot (Point A), it suggests a random nearby step (Point B) and compares their posterior densities.</p>
            <ul>
                <li><strong>The Uphill Move:</strong> If Point B has a higher density (more probable), the algorithm always accepts and moves there.</li>
                <li><strong>The Downhill Gamble:</strong> If Point B is lower, it doesn't automatically reject it. Instead, it accepts the move with a probability based on the ratio of the two heights (e.g., if B is 70% as high as A, there is a 70% chance to move).</li>
                <li><strong>The Outcome:</strong> If accepted, B becomes the next sample; if rejected, it stays put and records A again. This willingness to occasionally step "downhill" prevents the algorithm from getting stuck on local peaks, ensuring it traverses valleys to fully map the distribution's true shape.</li>
            </ul>
        </div>
    </div>
</details>

    <!-- SECTION 4 -->
    <details class="section">
        <summary>3. Types of Priors</summary>
        <div class="section-content">
            <div class="subsection">
                <span class="subsection-title">Conjugate Priors</span>
                <p>"Same family in, same family out."</p>
                
            </div>
            <div class="subsection">
                <span class="subsection-title">Objective Priors</span>
                <p>â€œIf you do not have information about a problem, then you do not have any reason to believe one outcome is more likely than any other.â€</p>
                <p><strong>Reparametrization:</strong> Describing the exact same system using different variables.<br>
                </p>
                <p><strong>JEFFREYâ€™S PRIOR:</strong> An objective prior invariant under reparametrization (consistent across units), making it the 1D "gold standard." It defines probability using Fisher Information, which measures likelihood sensitivity.<br><br>Fisher Information: It maps the "curvature" of the parameter space. It assigns more probability mass to high-sensitivity regions (where small nudges to the parameter drastically change the likelihood) and less to flat areas. This ensures the prior reflects information density rather than just scale.<br><br>
                <p><strong>REFERENCE PRIORS:</strong> Maximize Kullback-Leibler Divergence; measures distance between posterior and prior distributions, with more distance being better [higher information distance]. By not encoding any bias on the prior, this lets the data speak as we collect more samples.<br>
                KL Divergence measures the "information distance" between two distributions, P(x) (posterior) and Q(x) (prior)</p>
            </div>
            <div class="subsection">
                <span class="subsection-title">Maximum Entropy (MaxEnt) Priors</span>
                <p>When we aren't totally clueless about a parameter's plausible values, we can use Maximum Entropy (MaxEnt) priors. By selecting the flattest prior possible that obeys your constraints, you maximize you admitted uncertainty.</p>
                <p>For example, in modeling interest rates, a half-normal prevents negative values. By maximizing entropy, we allow the data to speak for itself.</p>
                <p><strong>LAGRANGIAN MULTIPLIERS</strong><br>
                <p>The math says: the probability at any point is just an exponential decay of how much that point violates your constraint(s).</p>
            </div>
            <div class="subsection">
                <span class="subsection-title">Prior Predictive Distribution</span>
                <p>Itâ€™s a sanity check. You draw parameters from your prior, then simulate data from them. If this "fake" data looks impossibleâ€”like negative heights or million-degree daysâ€”you know your prior is unrealistic and needs tightening.</p>
            </div>
        </div>
    </details>
</div>
</details>

    <!-- PART II -->
    <details class="part">
        <summary>Part II: Diagnostics & Workflow</summary>
        <div class="part-content">
            <span class="focus-line">Focus: Analysis, Convergence, HMC, Comparison</span>

<!-- SECTION 5 -->
<details class="section">
    <summary>1. Exploratory Analysis</summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">Bayesian Test Statistic (T-Stat)</span>
            
            <p>Think of <em>ğ’¯</em> as a "yardstick" chosen to measure a specific feature of the data, such as the average, the standard deviation, or the maximum value.</p>
            
            <ul style="margin-top: 5px; padding-left: 20px;">
                <li><strong>ğ’¯_obs:</strong> The value measured from the real data.</li>
                <li><strong>ğ’¯_sim:</strong> The value measured from fake data generated by the model.</li>
            </ul>
        </div>
        
        <div class="subsection">
            <span class="subsection-title">Bayesian P-Values</span>
            
            <p>This is simply a percentile ranking. It calculates the proportion of times the model's simulated data resulted in a higher value than the real data.</p>
            
            <p style="text-align: center; margin: 10px 0; font-weight: bold;">
                ğ‘_B = Proportion of (ğ’¯_sim > ğ’¯_obs)
            </p>
            
            <hr style="opacity: 0.3; margin: 10px 0;">
            
            <p><strong>How to Interpret:</strong></p>
            <ul style="margin-top: 5px; padding-left: 20px;">
                <li style="margin-bottom: 10px;">
                    <strong>ğ‘_B â‰ˆ 0.5 (Ideal):</strong> The model fits well. The real data sits comfortably in the middle of the model's predictions, looking just like a typical simulation.
                </li>
                <li>
                    <strong>ğ‘_B near 0 or 1 (Bias):</strong> The model is systematically failing.
                    <ul style="margin-top: 5px; padding-left: 20px; opacity: 0.9;">
                        <li><em>Near 1 (e.g., 0.99):</em> The model consistently predicts values higher than reality.</li>
                        <li><em>Near 0 (e.g., 0.01):</em> The model consistently predicts values lower than reality.</li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
</details>
<!-- SECTION 6 -->
<details class="section">
    <summary>2. Convergence: R-Hat, ESS, MCSE</summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">1. R Hat: Convergence Factor [Gelman-Rubin]</span>
            <p>MCMC methods have theoretical guarantees of correctness regardless of starting point, but only for infinite samples. In practice, we need ways to assess convergence for finite samples.</p>
            <p>Ë†R compares the spread between different chains to the spread within them. If Ë†R > 1.01, your chains are effectively "disagreeing" or haven't mixed yet â€” the simulation isn't finished, so don't trust the results.</p>
            
        </div>
        <div class="subsection">
            <span class="subsection-title">2. Effective Sample Size (ESS)</span>
            <p>Check this second to measure precision.</p>
            <p>Once chains have converged (Ë†R â‰ˆ 1), ESS tells you the volume of useful information in your samples.</p>
            <p><strong>What it is:</strong><br>
            ESS estimates the number of independent data points your MCMC chain is equivalent to. Because MCMC samples are correlated (â€œstickyâ€), 4,000 steps might only provide as much information as 800 independent draws.</p>
            <p><strong>How it is computed:</strong><br>
            It penalizes the total sample count (N) based on autocorrelation.</p>
            <p>1. Measure Stickiness: Calculate the correlation between samples at various lags (ÏÌ‚_k).</p>
            <p>2. Sum & Divide: Sum the positive correlations to find the â€œinefficiency factor,â€ then divide the total count by it.</p>
            <p>ESS = N / Sum of Autocorrelations</p>
            <p>High correlation â†’ High inefficiency â†’ Low ESS.</p>
            <p><strong>Why it is helpful:</strong><br>
            It measures precision.</p>
            <ul>
                <li>High ESS: Your posterior estimates (mean, intervals) are stable and accurate.</li>
                <li>Low ESS: Your estimates are noisy and unreliable, even if the model has converged (RÌ‚ â‰ˆ 1).</li>
            </ul>
        </div>
        <div class="subsection">
            <span class="subsection-title">3. MCSE (Monte Carlo Standard Error)</span>
            <p><strong>What it is:</strong><br>
            MCSE measures "simulation noise." Because MCMC finds answers by random sampling rather than solving an exact equation, the result wobbles slightly if you run the code again. MCSE quantifies this computational error.</p>
            
            <p><strong>The Calculation:</strong></p>
            <div style="font-family: 'Times New Roman', serif; font-size: 1.1em; margin: 15px 0; display: flex; align-items: center; gap: 10px;">
                <span>MCSE = </span>
                <div style="display: inline-block; vertical-align: middle; text-align: center;">
                    <div style="border-bottom: 1px solid currentColor; padding-bottom: 2px;">Posterior SD</div>
                    <div style="padding-top: 2px;">&radic;<span style="text-decoration: overline;">ESS</span></div>
                </div>
            </div>

            <p>It compares the simulation noise to the <strong>Posterior Standard Deviation (SD)</strong>. The Posterior SD represents the actual uncertainty in your result based on the evidence (the spread of plausible values).</p>

            <p><strong>How it assesses Quality:</strong><br>
            It determines if your estimate is stable enough to trust.</p>

            <p><strong>The Logic:</strong> Higher ESS (more info) reduces MCSE (less wobble).</p>

            <p><strong>The Quality Check:</strong> You want the MCSE to be tiny compared to the Posterior SD. This ensures the uncertainty you report comes from your data, not just the computer's random variation.</p>
        </div>
        <div class="subsection">
            <span class="subsection-title">MCMC Workflow Summary</span>
            <p>1. Ë†R (Gelman-Rubin statistic)<br>
            Confirms chains have mixed (validity). Check if Ë†R â‰ˆ 1 (Ë†R â‰¤ 1.01 is safe).</p>
            <p>2. ESS (Effective Sample Size)<br>
            Measures the volume of independent information (quantity). Aim for ESS >400 or >1000 per chain for stable estimates.</p>
            <p>3. MCSE (Monte Carlo Standard Error)<br>
            Uses ESS to assess if your estimate is precise enough for your scientific question (quality).</p>
        </div>
        <div class="subsection">
            <span class="subsection-title">Trace Plot: Monitoring Convergence at a glance</span>
            <p>"Fuzzy caterpillar" is a great rule of thumb, but not fail-safe. It implies mixing, but watch for:<br>
            1. Sticking: Subtle "flat shelves" mean the sampler froze.<br>
            2. Local Traps: A chain can look stable while stuck in one peak, missing others.</p>
            <p>Treat visuals as a sniff test. Always verify with R^ (to check consensus) and ESS (to check volume) to ensure the fuzz is real.</p>
        </div>
    </div>
</details>

            <!-- SECTION 7 -->
            <details class="section">
                <summary>3. Hamiltonian Monte Carlo (HMC)</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">How HMC Works Step by Step</span>
                        <p>HMC treats the posterior distribution like a physical terrain to explore it efficiently. Here is how the machinery works, step-by-step:</p>
                        <p><strong>1. The Landscape (Negative Log-Probability)</strong><br>
                        To apply physics to statistics, we treat the probability distribution as a "Potential Energy" field.<br>
                        â€¢ The Inversion: In physics, gravity pulls objects to the lowest energy state (the bottom of a valley). In statistics, we want the highest probability (the top of a peak). By taking the negative of the probability, we flip the map upside down: high-probability peaks become deep valleys that the sampler naturally "falls" into.<br>
                        
                        <p><strong>2. Momentum (The Kick)</strong><br>
                        To move around this landscape, we give the sampler a physical "kick." We pair every parameter with an auxiliary momentum variable, sampled from a proposal distribution (typically a Gaussian).<br>
                        The shape of this distribution (the mass matrix) acts like a vehicle's suspension. If tuned correctly to the valley's geometry, it allows the sampler to traverse long distances and complex correlations efficiently, rather than stumbling blindly like standard random-walk samplers.</p>
                        <p>In practice, HMC spends a "warm-up" phase learning the shape of the valley to select the appropriate matrix:<br>
                        â€¢ Identity Matrix: The default setting. It assumes all parameters have the exact same scale and no correlations. It often struggles with real-world data (e.g., comparing "Income" to "Age").<br>
                        â€¢ Diagonal Matrix: The industry standard. It estimates the variance of each parameter independently. It effectively "squishes" long dimensions and stretches short ones to make the probability valley look like a round bowl.<br>
                        â€¢ Dense Matrix: The "heavy artillery" for highly correlated parameters. If the valley runs diagonally, a Dense matrix captures the covariance and rotates the entire coordinate system, turning a tight, diagonal ravine into a perfectly aligned bowl.</p>
                        <p><strong>3. Simulation</strong><br>
                        The sampler trades Potential Energy for Kinetic Energy: it speeds up as it dives into high-probability valleys and slows down as it climbs low-probability hills. This allows it to explore the entire shape of the "bowl" (the posterior) rather than just sitting at the bottom.</p>
                        <p><strong>4. Acceptance (Energy Conservation)</strong><br>
                        In a perfect physical system, Total Energy (Potential + Kinetic) is conserved. However, because computer simulations use discrete time steps, tiny errors creep in. We compare the energy at the start and end of the trajectory. If the energy is roughly conserved, the move is accepted. This correction step ensures the resulting samples are statistically valid.</p>
                        <p><strong>5. Divergences (The "Check Engine" Light)</strong><br>
                        If the landscape is too treacherousâ€”like a "funnel" with a dangerously steep neckâ€”the simulation step size may fail to capture the curvature. When this happens, the physics break, and energy shoots to infinity.<br>
                        These divergent transitions are invaluable diagnostics. They usually cluster in specific problem areas, pinpointing exactly where the geometry is broken. This guides reparameterization: the process of mathematically rewriting variables to reshape the terrain without changing predictions. </p>
                    </div>
                   
                </div>
            </details>

            <!-- SECTION 8 -->
            <details class="section">
                <summary>4. Comparing Models</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">P_Loo (Effective Parameters via LOO)</span>
                        <p><strong>Leave One Out Mechanics Reminder</strong><br>
                        LOO is just a procedure. It produces no numbers or results on its own without a metric (like ELPD, MSE, or Accuracy) to calculate during that procedure.<br>
                        You cannot "just LOO"â€”you must LOO with a scorecard.</p>
                        <p><strong>STEPS</strong><br>
                        1. Hide y_i (leave it out).<br>
                        2. Train the model on the remaining n-1 points.<br>
                        3. Score the log probability of the hidden y_i.<br>
                        Repeat this n times (once for every point) and sum the scores.<br>
                        This removes the "double-dipping" bias, providing a realistic measure of how well the model generalizes to new data rather than memorizing the training set.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title"><strong>Pareto Shape Parameter</strong></span>
                        <p> IDENTIFYING OVER-EMPHASIZED DATAPOINTS <br>
                        <p>Estimates how much the model relies on a single data point.</p>
                        <p>- Low Pareto Values<br>
                        The data point is normal; the model understands it easily alongside the others.</p>
                        <p>- High Pareto Values (> 0.7):<br>
                        The data point is highly influential and "surprising." The model struggles to fit it and is likely overfitting. Removing this point would drastically change predictions. It also signals that the posterior is too heavy-tailed for reliable approximation.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">p_loo: Effective Number of Parameters</span>
                        <p>pâ‚—â‚’â‚’ measures the gap between in-sample fit (memorization) and out-of-sample generalization.</p>
                        <p><strong>Formula</strong><br>
                        pâ‚—â‚’â‚’ = lppd âˆ’ elpdâ‚—â‚’â‚’<br>
                        - lppd: LPPD is a score of how well the model's parameters generate the historical data.<br>
                        - elpdâ‚—â‚’â‚’: ELPD is a score of how well the model generates new data.</p>
                        <p><strong>Interpretation</strong><br>
                        pâ‚—â‚’â‚’ represents the model's overfitting tendency.<br>
                        - Ideal: pâ‚—â‚’â‚’ â‰ˆ actual number of parameters (e.g., ~5 for 5 variables).<br>
                        - Very large pâ‚—â‚’â‚’: Model is overly flexible and overfitting noise heavily.<br>
                        - pâ‚—â‚’â‚’ >> actual parameters: Model relies too much on influential data points (high leverage) or the prior is too weak.</p>
                    </div>
                </div>
            </details>
        </div>
    </details>

    <!-- PART III -->
    <details class="part">
        <summary>Part III: Advanced Models</summary>
        <div class="part-content">
            <span class="focus-line">Focus: Lasso, Statespace, Kalman Filter</span>

            <!-- SECTION 9 -->
            <details class="section">
                <summary>1. Laplace Priors (Bayesian Lasso)</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">The "Skeptical" Distribution</span>
                        <p>"Irrelevant until proven Essential."</p>
                        <p><strong>How it works as a test:</strong> When you aren't sure if a variable (like a specific sensor, a gene, or a market indicator) is predictive, you assign it a Laplace Prior.<br>
                        1. The Prior pulls every single variable toward zero (meaning: "this variable has no effect").<br>
                        2. The Data fights back. If a variable effectively lowers the error rate, the Data pulls it away from zero.<br>
                        3. The Result: Because the Laplace peak is so sharp, weak variables slide all the way down to exactly zero and "die." Only the variables with genuine, strong predictive power can survive the pull and remain non-zero.</p>
                        <p><strong>When to use it:</strong><br>
                        â€¢ High-Dimensional "Fishing": You have 1,000 potential variables but suspect only 5 actually matter.<br>
                        â€¢ Expensive Data: When keeping a variable "active" costs money (e.g., requires keeping a sensor online), you want to zero out the useless ones.<br>
                        â€¢ Interpretability: You need to explain to a human why the prediction happened (it's easier to point to 3 active variables than 1,000 slightly active ones).</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Sector Examples</span>
                        <p><strong> Defense: Acoustic Signature Classification (Sonar)</strong><br>
                        The Unknown: A submarine's passive sonar picks up a complex noise in the water. This sound is a mix of thousands of frequencies. You need to know if this is a whale, a merchant ship, or an enemy submarine. Most frequencies are just "ocean background noise," but you don't know which frequencies contain the hidden mechanical hum of a propeller.<br>
                        The Application: You treat every frequency band (Hz) as a variable. You apply a Laplace Prior to the amplitude weights of these bands.<br>
                        The Result: The Laplace Prior aggressively suppresses the thousands of frequencies related to waves and shrimp (background noise), forcing their weights to zero. It leaves behind a "sparse" set of specific non-zero frequenciesâ€”perhaps a harmonic series at 50Hz, 100Hz, and 150Hz.<br>
                        â€¢ Outcome: This sparse "fingerprint" is isolated from the noise. The system instantly recognizes this specific harmonic pattern as the signature of a specific class of diesel-electric engine, ignoring the rest of the ocean's chaotic noise.</p>
                        
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Hamiltonian Monte Carlo + LaPlace Priors = Bayesian Lasso</span>
                        <p>HMC uses gradients to navigate parameter space like a skateboarder in a half-pipe. A Laplace Prior modifies this pipe, carving a deep, narrow trench at zero.</p>
                        <p>[[As HMC samples, it naturally slides the coefficients of irrelevant variables into this trench, trapping their probability mass near zero.<br>
                        However, essential features possess enough "data energy" (evidence) to push the skateboarder up the walls, keeping their values away from zero.]]</p>
                        <p>This combination (often called the Bayesian Lasso) is powerful because HMC explores high-dimensional spaces efficiently. It doesn't just select features; it quantifies certainty. You get a histogram for every variable: if the samples pile up at zero, itâ€™s noise; if they hover strictly away from zero, the feature is essential.</p>
                    </div>
                </div>
            </details>

            <!-- SECTION 10 -->
            <details class="section">
                <summary>2. Statespace Modeling</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">State Space Modeling</span>
                        <p>Track a system that changes over time, where you cannot measure the variables you actually care about.</p>
                                           
                    
                        <p><strong>Latent State:</strong> Information not directly observable, but that can be approximated using transformed data.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">1. FILTERING</span>
                        <p>It is a rhythm of Prediction and Correction.<br></p>
                        
                        
                       
                        <p><strong>Best illustrated with an example</strong><br>
                        Imagine you are driving into a tunnel and your GPS loses signal.<br>
                        Predict (The Physics): Even without signal, the GPS assumes you are still moving forward at 60mph. It uses the previous state (ğ±â‚œâ‚‹â‚) to predict the current state (ğ±â‚œ).<br>
                        Update (The Correction): Suddenly, you exit the tunnel and the satellite gets a ping (ğ²â‚œ). The ping says you are 10 meters back from where the model guessed.<br>
                        Filter: The model combines its guess with the new data. If the satellite signal is usually noisy/unreliable, it trusts the guess more. If the signal is precise, it trusts the data more. The result is the Filtered Estimate.</p>
                        
                        <p><strong>When to the marginal distribution:</strong><br>
                        You use this whenever you need to estimate a variable that is dynamic (changing) and indirectly observed (noisy).<br>
                        Robotics/GPS: Your phone uses this (often a Kalman Filter). The GPS sensor is accurate to ~10m, but your blue dot on maps moves smoothly. That smooth movement is the hidden state ğ± being filtered from the noisy GPS data ğ².<br>
                        Finance: You observe stock prices (ğ²), but you want to trade based on "market volatility" (ğ±). Volatility isn't a number you can download; you must infer it from the price swings.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">2. SMOOTHING</span>
                        <p>You aren't predicting tomorrow; you are refining the history.<br>
                        It computes the probability of a past state ğ±â‚– using the entire dataset ğ²â‚€:â‚œâ€”meaning it uses observations from before, during, and after the specific moment you are analyzing.</p>
                        <p><strong>What does it do?</strong><br>
                        It refines the history. Because it has access to "future" data (relative to the state ğ±â‚– being estimated), it eliminates false moves and noise that the Filter fell for in real-time.<br></p>
                        
                        
                        
                        <p><strong>When to use it?</strong><br>
                        You use Smoothing for retrospective analysis or offline processing, where you have recorded data and need the highest accuracy possible, not real-time responsiveness.<br>
                        * Climate Science: Reconstructing past temperatures (ğ±) using ice cores and tree rings (ğ²). You aren't predicting tomorrow; you are refining the history of the last 100 years.<br></p>
                        
                    </div>
                </div>
            </details>

            <!-- SECTION 11 -->
            <details class="section">
                <summary>3. Linear Gaussian SSM</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">Explained through a missile navigation system</span>
                        <p><strong>1. The State Evolution Equation</strong><br>
                        <span class="code-block">ğ—â‚œ = ğ…â‚œ ğ—â‚œâ‚‹â‚ + ğ›ˆâ‚œ</span><br>
                        This equation defines the "physics" of the hidden system.<br>
                        * ğ—â‚œ (State Vector): A column of numbers representing the complete internal status of the system. For a moving object, this vector might contain [position, velocity, acceleration]. It holds all dimensions required to predict the future, even those not directly visible.<br>
                        * ğ…â‚œ (Transition Matrix): It encodes the rules of interaction between state variables. It is a linear operator that multiplies the previous state vector (ğ—â‚œâ‚‹â‚) to calculate the new state. For example, it mathematically enforces that "current position = previous position + previous velocity."<br>
                        * ğ›ˆâ‚œ (Process Noise Vector): A number column of random shocks representing external realities not captured by your physics engine (e.g., wind gusts or wheel slip).<br>
                        * ğâ‚œ (Process Covariance Matrix): The numbers on the diagonal tell you the magnitude (variance) of the shocks for each variable. The off-diagonal numbers tell you the correlationsâ€”if the velocity gets a random shock, does the position also tend to get a shock? </p>
                        <p><strong>2. The Observation Equation</strong><br>
                        <span class="code-block">ğ˜â‚œ = ğ‡â‚œ ğ—â‚œ + ğ›†â‚œ</span><br>
                        This equation defines the "lens" through which we view the system.<br>
                        * ğ˜â‚œ (Observation Vector): The raw data collected by your sensors at time ğ‘¡. This vector typically has fewer dimensions than the state vector (e.g., a GPS sensor reads [position], but cannot read [velocity]).<br>
                        * ğ‡â‚œ (Observation Matrix):  It acts as a projection operator, mapping the high-dimensional "State Space" down to the lower-dimensional "Measurement Space."  This matrix describes the relationship between the hidden truth and the sensor reading.<br>
                        * ğ›†â‚œ (Measurement Noise Vector): A vector representing the random error or "static" inherent in the sensors.<br>
                        * ğ‘â‚œ (Measurement Covariance Matrix): This matrix quantifies the reliability of your sensors. A high value on the diagonal means that specific sensor is very noisy (high variance); a low value means it is precise. The Kalman Filter uses this matrix to decide how much to "trust" the incoming data ğ˜â‚œ versus its own prediction from Step 1.</p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Operational Interactions: The Mechanics of the Matrix</span>
                        <p> ğ…â‚œ * ğ—â‚œâ‚‹â‚</p>
                        <p><strong>1. The State Update: Linear Combination and Displacement</strong><br>
                        [[[ ğ…â‚œ ğ—â‚œâ‚‹â‚ + ğ›ˆâ‚œ<br>
                        The product of the transition matrix [ğ…â‚œ] and the previous values of the state vector [ğ—â‚œâ‚‹â‚] is used to ensure the transformation rules are being enforced. ]]]<br>
                        â–¬Î¹ğ“†ƒ<br>
                                              
                        
                        <p><strong>2. The Observation Projection: Translation and Selection</strong><br>
                        [[[ ğ‡â‚œ ğ—â‚œ<br>
                        The product of the obs matrix [ğ‡â‚œ ] by the state vector [ğ—â‚œ]is to filter out latent variables. ]]]<br>
                        By performing the multiplication, you are essentially saying:<br>
                        "Take the reality of the past (ğ—â‚œâ‚‹â‚) and force it through the logic of my physics engine (ğ…â‚œ) to calculate where it must be now."<br>
                        â–¬Î¹ğ“†ƒ<br>
                        
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Generative Process of the Linear Gaussian State Space Model (SSM)</span>
                        <p>The generative process asks, "If the system works like this, what kind of data would it produce?"</p>
                        
                        <p><strong>1. Equation 1: The Physics (Process Model)</strong><br>
                        <span class="code-block">ğ—â‚œ âˆ¼ ğ’©(ğ…â‚œ ğ—â‚œâ‚‹â‚, ğâ‚œ)</span><br>
                        This equation says: "The State at time ğ‘¡ is a random draw from a Bell Curve."</p>
                        <p>A. Why is the Mean ğ…â‚œ ğ—â‚œâ‚‹â‚?<br>
                        In a Normal distribution, the Mean represents the "perfect," "expected," or "most likely" value.<br>
                        The term ğ…â‚œ ğ—â‚œâ‚‹â‚ is your deterministic physics engine. It applies the transformation rules (e.g., position + velocity) to the previous state.<br>
                        If we lived in a perfect universe with no wind, friction, or entropy, the state would be exactly ğ…â‚œ ğ—â‚œâ‚‹â‚.<br>
                        Therefore, we center the bell curve right on top of this physical prediction. It is our "best guess."</p>
                        <p>B. Why is ğâ‚œ the Sigma (Covariance)?<br>
                        In a standard bell curve, Sigma (Ïƒ) defines the width. In this vector equation, ğâ‚œ is the Covariance Matrix.<br>
                        This represents the "Process Noise." It accounts for external realities the physics engine ignored (wind gusts, wheel slips).</p>
                        <p><strong>2. Equation 2: The Sensor (Observation Model)</strong><br>
                        <span class="code-block">ğ˜â‚œ âˆ¼ ğ’©(ğ‡â‚œ ğ—â‚œ, ğ‘â‚œ)</span><br>
                        This equation says: "The Data reading at time ğ‘¡ is a random draw from a Bell Curve centered around the truth."</p>
                        <p>A. Why is the Mean ğ‡â‚œ ğ—â‚œ?<br>
                        ğ‡â‚œ is the "lens" or "mask" matrix. It converts the hidden state (Truth) into what the sensor should theoretically see.<br>
                        If the sensor were perfect, the reading ğ˜â‚œ would equal ğ‡â‚œ ğ—â‚œ exactly.<br>
                        Therefore, we center the probability distribution on this "Ideal Reading."</p>
                        <p>B. Why is ğ‘â‚œ the Sigma (Covariance)?<br>
                        ğ‘â‚œ represents Measurement Noise.<br>
                        This defines the quality of your hardware. A cheap sensor has a high ğ‘ (wide spread, fuzzy data). An expensive, precision sensor has a low ğ‘ (narrow spread, sharp data).</p>
                        <p><strong>3. Summary of Interactions</strong><br>
                        Kalman Filter mathematically weighs two competing uncertainties:<br>
                        The Physics Uncertainty [unobservable state] (ğâ‚œ): "How much do I trust my prediction?"<br>
                        The Sensor Uncertainty [observable data] (ğ‘â‚œ): "How much do I trust my data?"<br>
                        If ğ is large and ğ‘ is small: The math "trusts" the data. The bell curve is wide for the prediction but narrow for the measurement, so the final estimate snaps to the measurement.<br>
                        If ğ is small and ğ‘ is large: The math "trusts" the physics. The data is too noisy, so the filter ignores the data and sticks to the trajectory calculated by ğ…â‚œ ğ—â‚œâ‚‹â‚.</p>
                    </div>
                </div>
            </details>

            <!-- SECTION 12 -->
            <details class="section">
                <summary>4. Kalman Filter</summary>
                <div class="section-content">
                    <div class="subsection">
                        <span class="subsection-title">The Mechanics</span>
                        <p>Think of the Kalman Gain as a dynamic mixing slider that moves automatically at every time step between 0 (Pure Physics) and 1 (Pure Data).</p>
                        <p><strong>1. The Mechanics of the Gain</strong><br>
                        The Gain compares the Predicted Uncertainty (derived from ğ) against the Measurement Uncertainty (ğ‘).<br>
                        <span class="code-block">ğŠâ‚œ â‰ˆ Uncertainty_Predict / (Uncertainty_Predict + Uncertainty_Measure)</span></p>
                    </div>
                    <div class="subsection">
                        <span class="subsection-title">Scenarios</span>
                        <p><strong>2. Scenario A: High ğ, Low ğ‘ (Trust the Data)</strong><br>
                        * The Situation: You are tracking an erratic drone (High Process Noise) with a laser precision tracker (Low Measurement Noise).<br>
                        * The Cycle: During the Predict step, the drone's erratic behavior makes the uncertainty "bubble" expand rapidly.<br>
                        * The Action: The math sees the Prediction is vague but the Sensor is sharp. The Kalman Gain shoots up (close to 1).<br>
                        * The Result: In the Update step, the filter aggressively snaps the state to the measurement, effectively resetting the prediction to match the laser.</p>
                        <p><strong>3. Scenario B: Low ğ, High ğ‘ (Trust the Physics)</strong><br>
                        * The Situation: You are tracking a heavy freight train (Low Process Noise) with a fuzzy analog camera (High Measurement Noise).<br>
                        * The Cycle: During the Predict step, the train's massive inertia means the uncertainty stays tightâ€”we know exactly where it should be.<br>
                        * The Action: The math sees the Sensor is a "shotgun blast" of noise compared to the tight Physics prediction. The Kalman Gain drops (close to 0).<br>
                        * The Result: In the Update step, the filter treats the observation as "static." It barely nudges the state, allowing the smooth physics trajectory to dominate.</p>
                        <p><strong>Summary</strong><br>
                        The Kalman Filter aids the cycle by optimizing the correction. It prevents the system from chasing "ghosts" (sensor noise) while ensuring it doesn't become "blind" to real changes in direction.</p>
                    </div>
                </div>
            </details>
        </div>
    </details>

</div>

</body>
</html>